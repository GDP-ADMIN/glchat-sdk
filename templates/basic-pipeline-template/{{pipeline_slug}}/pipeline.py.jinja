"""{{pipeline_display_name}} Builder.

Authors:
    {{author_name}} ({{author_email}})

References:
    None
"""

from typing import Any

from gllm_generation.response_synthesizer import StuffResponseSynthesizer
from gllm_pipeline.pipeline.pipeline import Pipeline
from gllm_pipeline.steps import step
from gllm_plugin.pipeline.pipeline_plugin import PipelineBuilderPlugin
from gllm_plugin.utils.get_catalog import get_catalog
from gllm_plugin.utils.get_lm_invoker import get_lm_invoker

from {{pipeline_slug}}.preset_config import {{pipeline_name}}PresetConfig
from {{pipeline_slug}}.state import {{pipeline_name}}State, {{pipeline_name}}StateKeys



class {{pipeline_name}}PipelineBuilder(PipelineBuilderPlugin[{{pipeline_name}}State, {{pipeline_name}}PresetConfig]):
    """{{pipeline_display_name}} pipeline builder.

    This pipeline will simply pass the user query to the response synthesizer.
    There are no prompt templates used in this pipeline.

    Inherits attributes from `PipelineBuilderPlugin`.
    """

    name = "{{pipeline_id}}"
    preset_config_class = {{pipeline_name}}PresetConfig

    def __init__(self):
        """Initialize the {{pipeline_display_name}} pipeline builder."""
        super().__init__()

    async def build(self, pipeline_config: dict[str, Any]) -> Pipeline:
        """Build the pipeline.

        Args:
            pipeline_config (dict[str, Any]): The pipeline configuration.

        Returns:
            Pipeline: The simple pipeline.
        """
        model_name = pipeline_config.get("model_name")
        model_kwargs = pipeline_config.get("model_kwargs", {})
        model_env_kwargs = pipeline_config.get("model_env_kwargs", {})

        response_synthesizer_step = step(
            component=self.build_response_synthesizer(model_name, model_kwargs, model_env_kwargs),
            input_state_map={
                "query": {{pipeline_name}}StateKeys.QUERY,
                "event_emitter": {{pipeline_name}}StateKeys.EVENT_EMITTER,
            },
            output_state={{pipeline_name}}StateKeys.RESPONSE,
            runtime_config_map={
                "user_multimodal_contents": "binaries",
                "hyperparameters": "hyperparameters",
            },
        )

        pipeline = Pipeline(
            steps=[
                response_synthesizer_step,
            ],
            state_type={{pipeline_name}}State,
        )

        return pipeline

    def build_initial_state(
        self, request: dict[str, Any], pipeline_config: dict[str, Any], **kwargs: Any
    ) -> {{pipeline_name}}State:
        """Build the initial state for pipeline invoke.

        Args:
            request (dict[str, Any]): The given request from the user.
            pipeline_config (dict[str, Any]): The pipeline configuration.
            **kwargs (Any): A dictionary of arguments required for building the initial state.

        Returns:
            {{pipeline_name}}State: The initial state.
        """
        return {{pipeline_name}}State(
            query=request.get("message"),
            response=None,
            event_emitter=kwargs.get("event_emitter")
        )

    def build_response_synthesizer(
        self, model_name: str, model_kwargs: dict[str, Any], model_env_kwargs: dict[str, Any]
    ) -> StuffResponseSynthesizer:
        """Build the response synthesizer component.

        Args:
            model_name (str): The model to use for inference.
            model_kwargs (dict[str, Any]): The model kwargs.
            model_env_kwargs (dict[str, Any]): The model env kwargs.

        Returns:
            StuffResponseSynthesizer: The response synthesizer component.
        """
        lm_invoker = get_lm_invoker(model_name, model_kwargs, model_env_kwargs)
        prompt_builder = get_catalog(self.prompt_builder_catalogs, "generate_response", model_name)
        response_synthesizer = StuffResponseSynthesizer.from_lm_components(prompt_builder, lm_invoker)
        return response_synthesizer
